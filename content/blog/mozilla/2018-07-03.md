Title: Making calls to WebAssembly fast and implementing anyref
Date: 2018-07-02 20:00
Author: Benjamin Bouvier
Tags: mozilla
Slug: mozilla-2018-h1
Lang: en

Since this is the end of the first half-year, I think it is a good time to
reflect and show some work I've been doing over the last few months, apart from
the regular batch of random issues, security bugs, reviews and the fixing of 24
bugs found by our [fuzzers](https://en.wikipedia.org/wiki/Fuzzing).

## Bug 1319203: Make JS to WebAssembly calls *blazingly* fast

If we want more WebAssembly (wasm) adoption, there shouldn't be a big costly
barrier between the two universes. That is, calls from one world to the other
should be fast. For a very long time, calls from JS to asm.js/WebAssembly have
been quite slow in Firefox. In fact, we didn't optimize them at all. For ease and speed of
implementation at the time, asm.js call activations (data structures recording
information about the function being currently called in the VM) were very different from
the JS ones, implying some other huge structural differences, like frame
iteration, i.e. the capability to construct a precise call stack at any point
during the execution of a program mixing JS and asm.js/WebAssembly, so as to be
able to construct `Error()` stack frames, or just tracing the stack for garbage
collection purposes. After many refactorings and low-level changes that took a
great bunch of last year for me, Spidermonkey was ripe for an optimization.

To give some context here, when we call from JS to asm.js/wasm, and the JS
caller hasn't been JIT-compiled (i.e. compiled to machine code by our
just-in-time compiler IonMonkey), the call passes through C++, does a bunch of
work and then calls into a piece of glue code directly written in assembly: the
*interpreter entry stub*. This stub is quite small: it just copies out the C++
arguments into the right places the wasm callee expects, sets up some small
machine state, calls the wasm function, then does error checking and eventually
returns to the C++ caller.

From Firefox 60, the JIT compiler makes no distinctions between calling a
JavaScript function or a WebAssembly function, meaning it uses the same call
optimizations for both kinds of function. A new piece of glue code, the *JIT
entry stub*, is generated for each exported function: it converts and unboxes
the arguments read from the JS JIT caller into the right primitive types as
expressed in the wasm function's signature, sets up some machine registers,
calls into the wasm callee and then converts the result back to a boxed value
the JS caller may understand.

This resulted in massive speedups over a variety of different situations: when
a wasm function is directly / indirectly / polymorphically called, or used as a
getter/setter, or called by `Function.prototype.call/apply`, when the call is
missing required arguments, etc. Here's a brief summary of the results, but
there might be a full-blown blog post about these optimizations coming on
[Mozilla Hacks](https://hacks.mozilla.org/) at some point in the future.
(calling 1 billion times into very simple functions, lower is better)

![Charts showing evolution of performance]({filename}/images/2018-07-wasm-calls.png)

This work is not entirely done yet: we can still even better optimize in the
case of a function call from JS when the callee is definitely known to be a
unique wasm target (monomorphic case); see the [tracking
bug](https://bugzilla.mozilla.org/show_bug.cgi?id=1437065).

(The bug's name was a reference to another old [another big
speedup](https://bugzilla.mozilla.org/show_bug.cgi?id=274784) that happened a
few years ago in Firefox.)

## Bug 1422043: Lazy entry stub generation

The previous bug resolution came with an important memory issue: every exported
function now generates a rather big chunk of code for the JIT entry, having an
impact on the memory occupied by the code itself. This would be fine in most
situations where the number of exported functions is generally low. But when
the wasm module exports a Table (think of the equivalent of a C++ function
table with signature checks), we have to assume that every single function,
including those not explicitly exported, needs entry stubs. Indeed, each
function can be eventually called through the Table, after calls to
[WebAssembly.Table.set](http://webassembly.github.io/spec/js-api/index.html#dom-table-set).
In fact, the existing code already suffered from this because of the
interpreter entries, but it had been largely amplified by the much larger JIT
entry stubs.

To fix this, we've decided to lazily generate all the entry stubs for functions
exported through a table. That is, if a function is *explicitly* exported, its
stubs will be generated at wasm compile time, but other functions won't have
stubs yet. If a non-exported function is called through a Table, we'll generate
the entry stubs the first time it is called. This involves some fun
interactions with our [tiered
compilation](https://hacks.mozilla.org/2018/01/making-webassembly-even-faster-firefoxs-new-streaming-and-tiering-compiler/)
mechanism, which can compile functions and create new entry stubs in the
background while the running thread will generate lazy ones.

Not only this fixed the memory regression introduced by bug 1319203, but it
actually made the situation even better than the baseline, because we didn't need
to generate those interpreter entries for table-exported functions by default anymore:

![Charts showing evolution of memory usage]({filename}/images/2018-07-wasm-stubs-memory.png)

Since it's not entirely readable from the chart: after the patches, the
AngryBots and ZenGarden entry stubs memory usages went down to respectively 262
and 362 KB.

## Bug 1447591: Remove wasm::BinaryToText

WebAssembly is a binary format, and there is an equivalent text format which
makes it easier to reason about it for us, poor human beings, and for debugging
purposes: the WebAssembly Text format, or *WAT* format that you. At some point,
the text format was directly generated in Spidermonkey. It was easier to
maintain it as a part of the
[debugger.html](https://github.com/devtools-html/debugger.html) project, where
it was rewritten in JavaScript, because it made the mapping between bytecode
offsets and text offsets (source maps) more consistent with the display, and it
could be useful in other places where this project is being used. For some
time, we've had both implementations live alongside, so I decided to rip out
the C++ one. It's not every day that you get a net loss of around 5,500 lines
of code, which is always nice: less code means fewer bugs and less
mainteance burden, especially when the code is dead.

## Bug 1445272 / 1450261: Implement basic `anyref` support

A new proposal has been made to the WebAssembly specification comittee a few
months ago: to add [reference
types](https://github.com/WebAssembly/reference-types) to the type system.
Reference types are a new way to represent a reference to any *host* values. In
a Web environment, this means being capable of playing with JavaScript values
within WebAssembly. This is a huge difference with the existing type system,
which only contains primitive types: integers represented on 32 or 64 bits,
IEEE754 floating-point numbers represented on 32 or 64 bits. This is also a
first step for implementing [garbage
collection](http://github.com/webassembly/gc) (GC) integration within
WebAssembly: since these reference values have been allocated on the GC heap in
JavaScript, they need to be traced during wasm execution.

The basic implementation of this feature in the first bug allows one to use a
new type, called `anyref`, as part of a function's signature or in local
variables, be it in a function definition or an imported function. This allows
using JS variables within wasm and pass them around to other JS functions. The
second bug implemented the capability to read and write `anyref` values in wasm
Globals [1]. Since Globals can be manipulated outside of the wasm Module thanks
to their JS API, and garbage collections can happen at any time in JS, we
needed to implement GC barriers to make sure that the stored value would not be
marked as unused during tracing. Our garbage collector does incremental marking
thus it needs pre-barriers; since it's also generational, it needs
post-barriers. There is good literature explaining why these barriers are
needed and what they do, so I will not expand too much on the topic.

Here's an example of usage at the time being (spoiler alert, all these things
might change, including the text format representation, type names, APIs,
everything):

```lisp
(module
    (func $alert (import "env" "alert") (param anyref))
    (global $global_ref (mut anyref) (ref.null anyref))
    (func (export "set_and_alert") (param $param anyref) (result anyref)
        ;; Put the previous value of $global_ref on the virtual value stack.
        get_global $global_ref
        ;; Get the argument anyref value and store it in $global_ref.
        get_local $param
        set_global $global_ref
        ;; Call the $alert method with the argument anyref value.
        get_local $param
        call $alert
        ;; The previous value of $global_ref is still on the stack and will be
        ;; returned.
    )
)
```

*Example of wasm text format using `anyref`.*

```js
(async function() {
    let { instance } = await WebAssembly.instantiate(wasmBinary, {
        env: {
            alert(obj) {
                alert(`Hello, ${obj.name}!`);
            }
        }
    });
    console.log(instance.exports.set_and_alert({
        name: 'world',
        secretVal: 42
    }));
    // alerts "Hello, world!", logs null

    console.log(JSON.stringify(instance.exports.set_and_alert({
        name: 'there'
    })));
    // alerts "Hello, there!", logs { name: 'world!', secretVal: 42 }
})();
```

*Example of JavaScript using the module defined above, passing JS values and
reading them from WebAssembly.*

This is a very preliminary prototype and it might change in the next few
months. If you feel adventurous, you can try it on Firefox Nightly by setting
the `about:config` pref `javascript.options.wasm_gc` to `true`; be aware that
the GC counterparts have not been entirely implemented yet, so this might
result in out-of-memory situations. In any case, if you see something, [say
something](https://bugzilla.mozilla.org/enter_bug.cgi?product=Core&component=Javascript%3A%20Web%20Assembly).

Say you are a compiler developer, and you would like to port your langage to
WebAssembly, and your language uses a GC. At the moment, the only way you can do
this is by compiling your garbage collector to WebAssembly, and it would be
backed by the wasm Module's memory. It is fine, but might not be efficient
because it involves a lot of bookkeeping data structures that will also live
within the wasm memory. Plus, there's already a very efficient, solidly tested,
constantly improving garbage collector in your browser that uses all the
possible dirty low-level tricks known to mankind, which is the GC being used
for JavaScript. What if we could give you access to the garbage collector
directly? Then you'd just need to give a way to define structures, and then
could use a set of opcodes to allocate them, read and write fields on them,
etc. At the moment, the reference types proposal only allows you to move these
values around, not to allocate or touch them; but all these operations can be
emulated through calls to imported JS functions, which then could be replaced
by the right GC opcodes. There's also code on Firefox Nightly to experiment
with defining your own data structures and using them, but it is very very
early. If you're interested in following us implementing more parts, this
[tracking
issue](https://bugzilla.mozilla.org/show_bug.cgi?id=1444925) might be of
interest.

[1] Think of a C++ "global" value, not a JavaScript "global".
